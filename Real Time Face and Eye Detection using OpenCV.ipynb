{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8db137c4-067e-494e-875d-963f81520b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f68deb2-9366-4cf8-8768-bd97afaad0de",
   "metadata": {},
   "source": [
    "# Load/Read image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eda86b46-5507-46d9-aa5e-2bd5e80d828e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load an image using 'imread' specifying the path to image \n",
    "img=cv2.imread(r\"G:\\Data Science Project\\Real Time Face and Eye Detection using OpenCV\\image_examples-20241202T060043Z-001\\image_examples\\Modi.jpg\",1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a313dfb-3d35-475e-8559-27ac2dea1efe",
   "metadata": {},
   "source": [
    "### Let's take a closer look at how images are stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96368e88-b168-4406-a3c3-550210559687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]]\n"
     ]
    }
   ],
   "source": [
    "print(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c21cc8-387f-4d59-bbf5-18a8bfb2fe29",
   "metadata": {},
   "source": [
    "### Shape gives the dimensions of the image array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38365b8f-3d19-420b-845f-c22b64e47f03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1358, 1500, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape\n",
    "\n",
    "#The 3D dimensions are 1358 pixels in height * 1500 pixels wide\n",
    "#3 means that there are 3 components (RGB) that make up this image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f5e8db-1e83-4067-86c5-f69a8d7ff95a",
   "metadata": {},
   "source": [
    "# Display the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1168ca7f-099e-45be-aff9-de7e30892457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To display our image variable, we use 'imshow'\n",
    "# The first parameter will be title shown on image window\n",
    "# The second parameter is the image variable\n",
    "cv2.imshow('PM', img)\n",
    "\n",
    "# 'waitkey' allows us to input information when a image window is open\n",
    "# By leaving it blank it just waits for anykey to be pressed before continuing. \n",
    "# By placing numbers (except 0), we can specify a delay for\n",
    "#how Long you keep the window open (time is in milliseconds here)\n",
    "cv2.waitKey(2000)\n",
    "\n",
    "#This closes all open windows\n",
    "# Failure to place this will cause your program to hang\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39205d22-7f63-409c-942e-def8b8bfe350",
   "metadata": {},
   "outputs": [],
   "source": [
    "img= cv2.imread(r\"G:\\Data Science Project\\Real Time Face and Eye Detection using OpenCV\\image_examples-20241202T060043Z-001\\image_examples\\Modi.jpg\")\n",
    "cv2.imshow(\"PM\", img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d133a17b-a282-4c03-a2c1-21ec83104935",
   "metadata": {},
   "source": [
    "# Save image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8f7004b-819e-4ca3-8184-11f331ea385a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simply use 'imwrite' specificing the file name and the image to be saved \n",
    "cv2.imwrite(\"pm_b_w.jpg\",img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04dac211-bb14-4ff7-9643-644b32964d8f",
   "metadata": {},
   "source": [
    "# Resize image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f21f6855-6276-4b9d-9afe-4ff78d08cf9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(r\"G:\\Data Science Project\\Real Time Face and Eye Detection using OpenCV\\image_examples-20241202T060043Z-001\\image_examples\\Modi.jpg\")\n",
    "\n",
    "resized_image= cv2.resize(img,(500,500))\n",
    "\n",
    "gray = cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "cv2.imshow('Modi Image', gray)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2f4bb2d-5f35-4511-a33f-1644f3ab005c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "679.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape[0]*0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b4403fb-bbe5-440c-b000-392b2158626d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "750.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape[1]*0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f213ae60-3a47-4f42-9dc6-24138ecca899",
   "metadata": {},
   "source": [
    "# Face Detection using HAAR Cascade Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b0996b1-5da1-4ed4-97d4-812050af5885",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we point OpenCV's CascadeClassifier function to where our classifier (XML file format) is stored\n",
    "face_classifier = cv2.CascadeClassifier(r\"G:\\Data Science Project\\Real Time Face and Eye Detection using OpenCV\\Haarcascades-20241202T060054Z-001\\Haarcascades\\haarcascade_frontalface_default.xml\")\n",
    "\n",
    "#Load our image then convert it to grayscale \n",
    "image = cv2.imread(r\"G:\\Data Science Project\\Real Time Face and Eye Detection using OpenCV\\image_examples-20241202T060043Z-001\\image_examples\\Modi.jpg\") \n",
    "image= cv2.resize(img, (500,500)) \n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "### Tuning Cascade Classifiers - detectMultiScale(input image, ***Scale Factor, ****Min Neighbors*) \n",
    "faces= face_classifier.detectMultiScale(gray,1.05,5)\n",
    "\n",
    "# Scale Factor - Specifies how much we reduce the image size each time we scale.\n",
    "\n",
    "#E.g. in face detection we typically use 1.3. This means we reduce the image by 30% each time it's shape #Smaller values, Like 1.05 will take longer to compute, but will increase the rate of detection.\n",
    "\n",
    "##Min Neighbors**\n",
    "\n",
    "# Specifies the number of neighbors each potential window should have in order to consider it a positive detection.\n",
    "#Typically set between 3-6. \n",
    "#It acts as sensitivity setting, Low values will sometimes detect multiples faces over a single face.\n",
    "#High values will ensure less false positives, but you may miss some faces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15b70cac-961b-496a-9538-366a19517fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[205  79 217 217]]\n"
     ]
    }
   ],
   "source": [
    "print(faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6be37b7-f7ed-49a6-a69d-fe25a6b11b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:26: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:26: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_5424\\2951522086.py:26: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces is ():\n"
     ]
    }
   ],
   "source": [
    "#We point OpenCV's CascadeClassifier function to where our face_classifier (XML file format) is stored\n",
    "face_classifier = cv2.CascadeClassifier(r\"G:\\Data Science Project\\Real Time Face and Eye Detection using OpenCV\\Haarcascades-20241202T060054Z-001\\Haarcascades\\haarcascade_frontalface_default.xml\")\n",
    "\n",
    "#Load our image then convert it to grayscale \n",
    "image = cv2.imread(r\"G:\\Data Science Project\\Real Time Face and Eye Detection using OpenCV\\image_examples-20241202T060043Z-001\\image_examples\\Modi.jpg\") \n",
    "image = cv2.resize(image, (500,500)) \n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "###Tuning Cascade Classifiers - detectMultiScale(input image,scale Factor,*Min Neighbors*)\n",
    "faces = face_classifier.detectMultiScale(gray,1.05,5)\n",
    "#Scale Factor - Specifies how much we reduce the image size each time we scale.\n",
    "\n",
    "#E.g. in face detection we typically use 1.3. This means we reduce the image by 30% each time it's scaled.\n",
    "#Smaller values, Like 1.05 will take Longer to Compute, but will increase the rate of detection.\n",
    "\n",
    "## Min Neighbors**\n",
    "\n",
    "#Specifies the number of neighbors each potential window should have in order to consider it a positive detection.\n",
    "#Typically set between 3-6. \n",
    "\n",
    "# It acts as sensitivity setting, low values will sometimes detect multiples faces over a single face.\n",
    "#High values will ensure Less  false positives, but you may miss some faces. \n",
    "\n",
    "#When no faces detected, face_classifier returns and empty tuple\n",
    "\n",
    "if faces is (): \n",
    "   print(\"No faces found\")\n",
    "\n",
    "#We iterate through our faces array and draw a rectangle\n",
    "\n",
    "#over each face in faces\n",
    "\n",
    "for (x,y,w,h) in faces:  \n",
    "    cv2.rectangle(image, (x,y), (x+w,y+h), (0,255,100), 1)\n",
    "\n",
    "cv2.imshow(\"Face Detection\",image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40951e4-9b25-451f-9709-19e6fee39b7d",
   "metadata": {},
   "source": [
    "# Face and Eye Detection Using HAAR Cascade Classifiers in Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de2583a3-3fd0-4551-ac2e-ac7985217f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:14: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:14: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_5424\\1725825220.py:14: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces is ():\n"
     ]
    }
   ],
   "source": [
    "face_classifier =cv2.CascadeClassifier(r\"G:\\Data Science Project\\Real Time Face and Eye Detection using OpenCV\\Haarcascades-20241202T060054Z-001\\Haarcascades\\haarcascade_frontalface_default.xml\")\n",
    "eye_classifier =cv2.CascadeClassifier(r\"G:\\Data Science Project\\Real Time Face and Eye Detection using OpenCV\\Haarcascades-20241202T060054Z-001\\Haarcascades\\haarcascade_eye.xml\")\n",
    "\n",
    "img = cv2.imread(r\"G:\\Data Science Project\\Real Time Face and Eye Detection using OpenCV\\image_examples-20241202T060043Z-001\\image_examples\\Modi.jpg\")\n",
    "\n",
    "resized_image= cv2.resize(img,(500,500))\n",
    "\n",
    "gray = cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY) \n",
    "\n",
    "faces = face_classifier.detectMultiScale(gray,1.3, 5)\n",
    "\n",
    "# When no faces detected, face classifier Send empty tuple\n",
    "\n",
    "if faces is ():\n",
    "    print(\"No Face Found\")\n",
    "\n",
    "for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(resized_image, (x,y), (x+w,y+h) ,(255,0,0),2)\n",
    "    roi_gray = gray[y:y+h, x:x+w]\n",
    "    roi_color = resized_image[y:y+h, x:x+w]\n",
    "    eyes = eye_classifier.detectMultiScale(roi_gray)\n",
    "    for (ex, ey, ew,eh) in eyes:\n",
    "        cv2.rectangle(roi_color, (ex,ey), (ex+ew, ey+eh), (0,255,0),2)\n",
    "\n",
    "cv2.imshow('img',resized_image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31be2df-8072-4a97-9883-15bb2266e272",
   "metadata": {},
   "source": [
    "# Capture a video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ce1b43c-ebc8-4ce3-853c-e907032ba275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing some Face Recognition with the webcam\n",
    "\n",
    "import cv2\n",
    "video = cv2.VideoCapture(0) #0--webcam\n",
    "\n",
    "while True:\n",
    "   check, frame = video.read() \n",
    "   gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) \n",
    "   cv2.imshow('Video',gray) \n",
    "   if cv2.waitKey(1) == ord('q'): \n",
    "        break\n",
    "\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97ed253-11f7-4866-9ae9-fe7fd3c5122c",
   "metadata": {},
   "source": [
    "# Face and Eye Detection Using HAAR Cascade Classifiers \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "946e1a8d-bbfe-40ba-ac47-20392a912c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function that will do the detections\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier(r\"G:\\Data Science Project\\Real Time Face and Eye Detection using OpenCV\\Haarcascades-20241202T060054Z-001\\Haarcascades\\haarcascade_frontalface_default.xml\") \n",
    "eye_cascade = cv2.CascadeClassifier(r\"G:\\Data Science Project\\Real Time Face and Eye Detection using OpenCV\\Haarcascades-20241202T060054Z-001\\Haarcascades\\haarcascade_eye.xml\")\n",
    "\n",
    "def detect(gray, frame):\n",
    "    faces = face_cascade.detectMultiScale(gray,1.3, 5)\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frame, (x,y), (x+w, y+h), (255, 0, 0), 2)\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = frame [y:y+h, x:x+w]\n",
    "        eyes = eye_cascade. detectMultiScale(roi_gray, 1.1, 3)\n",
    "        for (ex, ey, ew, eh) in eyes:\n",
    "             cv2.rectangle(roi_color, (ex, ey), (ex+ew, ey+eh), (0, 255, 0), 2)\n",
    "    return frame\n",
    "\n",
    "#Doing some Face Recognition with the webcam\n",
    "\n",
    "video = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    check, frame = video.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    Canvas = detect(gray, frame)\n",
    "    cv2.imshow('Video', Canvas)\n",
    "    if cv2.waitKey(1)== ord(\"q\"):\n",
    "        break\n",
    "\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af46fc1c-71ab-451d-b6d8-46207173e8b0",
   "metadata": {},
   "source": [
    "# Pedistrian Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94566805-2b74-4688-a88c-07e5cdb7fda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "#Create our body classifier\n",
    "body_classifier = cv2.CascadeClassifier(r\"G:\\Data Science Project\\Real Time Face and Eye Detection using OpenCV\\Haarcascades-20241202T060054Z-001\\Haarcascades\\haarcascade_fullbody.xml\")\n",
    "\n",
    "#Initiate video capture for video file\n",
    "cap = cv2.VideoCapture(r\"G:\\Data Science Project\\Real Time Face and Eye Detection using OpenCV\\image_examples-20241202T060043Z-001\\image_examples\\walking.avi\")\n",
    "\n",
    "#Loop once video is successfully Loaded \n",
    "while cap.isOpened():\n",
    "\n",
    "    #Read first frame\n",
    "    check, frame = cap.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) \n",
    "    #Pass frame to our body Classifier\n",
    "    bodies = body_classifier.detectMultiScale(gray, 1.2,3)\n",
    "    \n",
    "    #Extract bounding boxes for any bodies identified\n",
    "    for (x,y,w,h) in bodies:\n",
    "         cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 255), 2) \n",
    "         cv2.imshow('Pedestrians', frame)\n",
    "\n",
    "    if cv2.waitKey(1)==ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "423316a6-3caf-4247-88ac-d78962b5c35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "#Create our body classifier\n",
    "car_classifier = cv2.CascadeClassifier(r\"G:\\Data Science Project\\Real Time Face and Eye Detection using OpenCV\\Haarcascades-20241202T060054Z-001\\Haarcascades\\haarcascade_car.xml\")\n",
    "\n",
    "#Initiate video capture for video file\n",
    "cap = cv2.VideoCapture(r\"G:\\Data Science Project\\Real Time Face and Eye Detection using OpenCV\\image_examples-20241202T060043Z-001\\image_examples\\cars.avi\")\n",
    "\n",
    "#Loop once video is successfully Loaded \n",
    "while cap.isOpened():\n",
    "   time.sleep(.05)\n",
    "\n",
    "   #Read first frame \n",
    "   check, frame = cap.read() \n",
    "   gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "   #Pass frame to our car classifier\n",
    "   cars = car_classifier.detectMultiScale(gray, 1.4, 2)\n",
    "\n",
    "   # Extract bounding boxes for any bodies identified \n",
    "   for (x,y,w,h) in cars:\n",
    "       cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 255), 2)\n",
    "       cv2.imshow(\"Cars\", frame)\n",
    "\n",
    "   if cv2.waitKey(1)==ord(\"q\"):\n",
    "      break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0b6260-1088-4d42-b102-eed41ed3f02e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
